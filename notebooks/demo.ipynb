{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with YOLOv8 - Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the object detection system for:\n",
    "- Loading and using pre-trained models\n",
    "- Training custom models\n",
    "- Running inference on images and videos\n",
    "- Evaluating model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics opencv-python matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # nano model (fastest)\n",
    "# model = YOLO('yolov8s.pt')  # small model\n",
    "# model = YOLO('yolov8m.pt')  # medium model\n",
    "# model = YOLO('yolov8l.pt')  # large model\n",
    "# model = YOLO('yolov8x.pt')  # xlarge model (most accurate)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Classes: {len(model.names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample image\n",
    "!wget -O sample.jpg https://ultralytics.com/images/bus.jpg\n",
    "\n",
    "# Run detection\n",
    "results = model.predict(\n",
    "    source='sample.jpg',\n",
    "    conf=0.25,\n",
    "    iou=0.45,\n",
    "    save=False\n",
    ")\n",
    "\n",
    "# Display results\n",
    "annotated_image = results[0].plot()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Object Detection Results')\n",
    "plt.show()\n",
    "\n",
    "# Print detections\n",
    "print(f\"\\nDetected {len(results[0].boxes)} objects:\")\n",
    "for box in results[0].boxes:\n",
    "    cls = int(box.cls[0])\n",
    "    conf = float(box.conf[0])\n",
    "    print(f\"  - {model.names[cls]}: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Video Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process video\n",
    "video_path = '../data/videos/sample.mp4'\n",
    "\n",
    "# Run detection on video\n",
    "results = model.predict(\n",
    "    source=video_path,\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    project='../outputs',\n",
    "    name='video_detection'\n",
    ")\n",
    "\n",
    "print(\"Video processing complete!\")\n",
    "print(f\"Output saved to: ../outputs/video_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Webcam Detection (Real-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This requires a webcam and may not work in all notebook environments\n",
    "# For real-time detection, use the detect.py script instead\n",
    "\n",
    "# Example command:\n",
    "# !python ../src/detect.py --source 0 --weights yolov8n.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset in YOLO format\n",
    "# Directory structure:\n",
    "# dataset/\n",
    "#   ├── images/\n",
    "#   │   ├── train/\n",
    "#   │   └── val/\n",
    "#   └── labels/\n",
    "#       ├── train/\n",
    "#       └── val/\n",
    "\n",
    "# Create dataset.yaml\n",
    "dataset_yaml = \"\"\"\n",
    "path: ../data/datasets/custom\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 3\n",
    "names:\n",
    "  0: class1\n",
    "  1: class2\n",
    "  2: class3\n",
    "\"\"\"\n",
    "\n",
    "with open('../configs/custom_dataset.yaml', 'w') as f:\n",
    "    f.write(dataset_yaml)\n",
    "\n",
    "print(\"Dataset configuration created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data='../configs/custom_dataset.yaml',\n",
    "    epochs=50,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    patience=10,\n",
    "    save=True,\n",
    "    project='../runs/train',\n",
    "    name='custom_model'\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = YOLO('../runs/train/custom_model/weights/best.pt')\n",
    "\n",
    "# Evaluate on validation set\n",
    "metrics = model.val(\n",
    "    data='../configs/custom_dataset.yaml',\n",
    "    conf=0.001,\n",
    "    iou=0.6\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training results\n",
    "results_csv = '../runs/train/custom_model/results.csv'\n",
    "df = pd.read_csv(results_csv)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Box Loss')\n",
    "axes[0, 0].plot(df['epoch'], df['train/cls_loss'], label='Class Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training Losses')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# mAP curves\n",
    "axes[0, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5')\n",
    "axes[0, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('mAP')\n",
    "axes[0, 1].set_title('Mean Average Precision')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Precision/Recall\n",
    "axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision')\n",
    "axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].set_title('Precision and Recall')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# F1 Score\n",
    "f1_score = 2 * (df['metrics/precision(B)'] * df['metrics/recall(B)']) / \\\n",
    "           (df['metrics/precision(B)'] + df['metrics/recall(B)'])\n",
    "axes[1, 1].plot(df['epoch'], f1_score, label='F1 Score', color='green')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('F1 Score')\n",
    "axes[1, 1].set_title('F1 Score')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "model = YOLO('../runs/train/custom_model/weights/best.pt')\n",
    "\n",
    "# Export to ONNX\n",
    "model.export(format='onnx', imgsz=640)\n",
    "\n",
    "# Export to TorchScript\n",
    "# model.export(format='torchscript', imgsz=640)\n",
    "\n",
    "# Export to CoreML (for iOS)\n",
    "# model.export(format='coreml', imgsz=640)\n",
    "\n",
    "print(\"Model exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple images\n",
    "image_dir = '../data/images/'\n",
    "output_dir = '../outputs/batch/'\n",
    "\n",
    "results = model.predict(\n",
    "    source=image_dir,\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    project=output_dir,\n",
    "    name='batch_results'\n",
    ")\n",
    "\n",
    "print(f\"Processed {len(results)} images\")\n",
    "print(f\"Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark inference speed\n",
    "model = YOLO('yolov8n.pt')\n",
    "dummy_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Warmup\n",
    "for _ in range(10):\n",
    "    _ = model.predict(dummy_image, verbose=False)\n",
    "\n",
    "# Benchmark\n",
    "iterations = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(iterations):\n",
    "    _ = model.predict(dummy_image, verbose=False)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "avg_time = (end_time - start_time) / iterations\n",
    "fps = 1 / avg_time\n",
    "\n",
    "print(f\"\\nBenchmark Results:\")\n",
    "print(f\"Average inference time: {avg_time*1000:.2f}ms\")\n",
    "print(f\"FPS: {fps:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Loading pre-trained YOLOv8 models\n",
    "- Running inference on images and videos\n",
    "- Training custom models\n",
    "- Evaluating model performance\n",
    "- Exporting models for deployment\n",
    "- Performance benchmarking\n",
    "\n",
    "For production deployment, use the provided API server (`src/api.py`) or command-line scripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
